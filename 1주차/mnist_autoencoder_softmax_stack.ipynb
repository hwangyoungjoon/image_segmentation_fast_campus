{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist=input_data.read_data_sets(\"/tmp/data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습에 필요한 설정값들 정의\n",
    "learning_rate_rmsprop=0.02\n",
    "learning_rate_gradient=0.5\n",
    "\n",
    "num_epochs=100\n",
    "batch_size=256\n",
    "display_step=1\n",
    "input_size=784\n",
    "hidden1_size=128\n",
    "hidden2_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력받기 위한 값 설정\n",
    "x=tf.placeholder(tf.float32,[None,784])\n",
    "y=tf.placeholder(tf.float32,[None,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# actoencoder 설정\n",
    "def build_autoencoder(x):\n",
    "    #784->128 피쳐를 줄이면서 중요한 피쳐들을 뽑아내는 과정\n",
    "    w1=tf.Variable(tf.random_normal([input_size,hidden1_size]))\n",
    "    b1=tf.Variable(tf.random_normal([hidden1_size]))\n",
    "    L1=tf.nn.sigmoid(tf.matmul(x,w1)+b1)\n",
    "    #128->64\n",
    "    w2=tf.Variable(tf.random_normal([hidden1_size,hidden2_size]))\n",
    "    b2=tf.Variable(tf.random_normal([hidden2_size]))\n",
    "    L2=tf.nn.sigmoid(tf.matmul(L1,w2)+b2)\n",
    "    #64->128 뽑아낸 피쳐들로부터 다시 원래 데이터를 다시 재구축하는 과정\n",
    "    w3=tf.Variable(tf.random_normal([hidden2_size,hidden1_size]))\n",
    "    b3=tf.Variable(tf.random_normal([hidden1_size]))\n",
    "    L3=tf.nn.sigmoid(tf.matmul(L2,w3)+b3)\n",
    "    #128->784 \n",
    "    w4=tf.Variable(tf.random_normal([hidden1_size,input_size]))\n",
    "    b4=tf.Variable(tf.random_normal([input_size]))\n",
    "    reconstructed_x=tf.nn.sigmoid(tf.matmul(L3,w4)+b4)\n",
    "    \n",
    "    return reconstructed_x, L2    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sofrmax_분류기\n",
    "def build_softmax_classify(x):\n",
    "    w_softmax=tf.Variable(tf.zeros([hidden2_size,10])) #원본이미지를 오토인코더로 최대한 압축해서 얻은 피쳐들을 다시 10차원으로\n",
    "    b_softmax=tf.Variable(tf.zeros([10]))\n",
    "    y_pred=tf.nn.softmax(tf.matmul(x,w_softmax)+b_softmax)\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 오토 인코더를 분류된 예측값, softmax로 표시된 예측값\n",
    "y_pred_autoencoder,extracted_feature=build_autoencoder(x)\n",
    "y_true_autoencoder=x  #오토 인코더의 타깃값은 들어온 x다 그래서 unsupervised가 가능\n",
    "y_pred_softmax=build_softmax_classify(extracted_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. pre-training: mnist 데이터 재구축을 목적으로하는 손실함수와 옵티마이저를 정의한다.\n",
    "pretraining_loss=tf.reduce_mean(tf.pow(y_true_autoencoder-y_pred_autoencoder,2)) # squared error 함수\n",
    "pretraining_train_step=tf.train.RMSPropOptimizer(learning_rate_rmsprop).minimize(pretraining_loss)\n",
    "\n",
    "# 2. fine-tuning: minist 데이터 분류를 목적으로 하는 손실함수와 옵티마이저를 구축한다.\n",
    "finetuning_loss=tf.reduce_mean(-tf.reduce_sum(y*tf.log(y_pred_softmax),reduction_indices=[1]))\n",
    "finetuning_train_step=tf.train.GradientDescentOptimizer(learning_rate_gradient).minimize(finetuning_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(epoch):1, pretrain_loss(손실): 0.167531\n",
      "반복(epoch):2, pretrain_loss(손실): 0.116206\n",
      "반복(epoch):3, pretrain_loss(손실): 0.100494\n",
      "반복(epoch):4, pretrain_loss(손실): 0.090414\n",
      "반복(epoch):5, pretrain_loss(손실): 0.084163\n",
      "반복(epoch):6, pretrain_loss(손실): 0.077649\n",
      "반복(epoch):7, pretrain_loss(손실): 0.077102\n",
      "반복(epoch):8, pretrain_loss(손실): 0.071776\n",
      "반복(epoch):9, pretrain_loss(손실): 0.070340\n",
      "반복(epoch):10, pretrain_loss(손실): 0.068978\n",
      "반복(epoch):11, pretrain_loss(손실): 0.064038\n",
      "반복(epoch):12, pretrain_loss(손실): 0.057467\n",
      "반복(epoch):13, pretrain_loss(손실): 0.056387\n",
      "반복(epoch):14, pretrain_loss(손실): 0.048961\n",
      "반복(epoch):15, pretrain_loss(손실): 0.050635\n",
      "반복(epoch):16, pretrain_loss(손실): 0.047107\n",
      "반복(epoch):17, pretrain_loss(손실): 0.044837\n",
      "반복(epoch):18, pretrain_loss(손실): 0.045899\n",
      "반복(epoch):19, pretrain_loss(손실): 0.043379\n",
      "반복(epoch):20, pretrain_loss(손실): 0.047415\n",
      "반복(epoch):21, pretrain_loss(손실): 0.042141\n",
      "반복(epoch):22, pretrain_loss(손실): 0.041209\n",
      "반복(epoch):23, pretrain_loss(손실): 0.040105\n",
      "반복(epoch):24, pretrain_loss(손실): 0.039625\n",
      "반복(epoch):25, pretrain_loss(손실): 0.037952\n",
      "반복(epoch):26, pretrain_loss(손실): 0.038614\n",
      "반복(epoch):27, pretrain_loss(손실): 0.037792\n",
      "반복(epoch):28, pretrain_loss(손실): 0.037018\n",
      "반복(epoch):29, pretrain_loss(손실): 0.034657\n",
      "반복(epoch):30, pretrain_loss(손실): 0.036225\n",
      "반복(epoch):31, pretrain_loss(손실): 0.035679\n",
      "반복(epoch):32, pretrain_loss(손실): 0.035812\n",
      "반복(epoch):33, pretrain_loss(손실): 0.033746\n",
      "반복(epoch):34, pretrain_loss(손실): 0.033369\n",
      "반복(epoch):35, pretrain_loss(손실): 0.033840\n",
      "반복(epoch):36, pretrain_loss(손실): 0.033150\n",
      "반복(epoch):37, pretrain_loss(손실): 0.034898\n",
      "반복(epoch):38, pretrain_loss(손실): 0.031672\n",
      "반복(epoch):39, pretrain_loss(손실): 0.030910\n",
      "반복(epoch):40, pretrain_loss(손실): 0.029199\n",
      "반복(epoch):41, pretrain_loss(손실): 0.029156\n",
      "반복(epoch):42, pretrain_loss(손실): 0.030807\n",
      "반복(epoch):43, pretrain_loss(손실): 0.028866\n",
      "반복(epoch):44, pretrain_loss(손실): 0.028796\n",
      "반복(epoch):45, pretrain_loss(손실): 0.028113\n",
      "반복(epoch):46, pretrain_loss(손실): 0.025793\n",
      "반복(epoch):47, pretrain_loss(손실): 0.026073\n",
      "반복(epoch):48, pretrain_loss(손실): 0.024758\n",
      "반복(epoch):49, pretrain_loss(손실): 0.027219\n",
      "반복(epoch):50, pretrain_loss(손실): 0.024958\n",
      "반복(epoch):51, pretrain_loss(손실): 0.024940\n",
      "반복(epoch):52, pretrain_loss(손실): 0.026254\n",
      "반복(epoch):53, pretrain_loss(손실): 0.028542\n",
      "반복(epoch):54, pretrain_loss(손실): 0.023987\n",
      "반복(epoch):55, pretrain_loss(손실): 0.025102\n",
      "반복(epoch):56, pretrain_loss(손실): 0.023926\n",
      "반복(epoch):57, pretrain_loss(손실): 0.022877\n",
      "반복(epoch):58, pretrain_loss(손실): 0.023715\n",
      "반복(epoch):59, pretrain_loss(손실): 0.022913\n",
      "반복(epoch):60, pretrain_loss(손실): 0.022808\n",
      "반복(epoch):61, pretrain_loss(손실): 0.022640\n",
      "반복(epoch):62, pretrain_loss(손실): 0.022884\n",
      "반복(epoch):63, pretrain_loss(손실): 0.022763\n",
      "반복(epoch):64, pretrain_loss(손실): 0.023779\n",
      "반복(epoch):65, pretrain_loss(손실): 0.022266\n",
      "반복(epoch):66, pretrain_loss(손실): 0.022367\n",
      "반복(epoch):67, pretrain_loss(손실): 0.024397\n",
      "반복(epoch):68, pretrain_loss(손실): 0.021155\n",
      "반복(epoch):69, pretrain_loss(손실): 0.020680\n",
      "반복(epoch):70, pretrain_loss(손실): 0.021088\n",
      "반복(epoch):71, pretrain_loss(손실): 0.021061\n",
      "반복(epoch):72, pretrain_loss(손실): 0.020600\n",
      "반복(epoch):73, pretrain_loss(손실): 0.020587\n",
      "반복(epoch):74, pretrain_loss(손실): 0.021164\n",
      "반복(epoch):75, pretrain_loss(손실): 0.021199\n",
      "반복(epoch):76, pretrain_loss(손실): 0.020174\n",
      "반복(epoch):77, pretrain_loss(손실): 0.020161\n",
      "반복(epoch):78, pretrain_loss(손실): 0.020638\n",
      "반복(epoch):79, pretrain_loss(손실): 0.019907\n",
      "반복(epoch):80, pretrain_loss(손실): 0.019876\n",
      "반복(epoch):81, pretrain_loss(손실): 0.019092\n",
      "반복(epoch):82, pretrain_loss(손실): 0.019802\n",
      "반복(epoch):83, pretrain_loss(손실): 0.018568\n",
      "반복(epoch):84, pretrain_loss(손실): 0.019435\n",
      "반복(epoch):85, pretrain_loss(손실): 0.020340\n",
      "반복(epoch):86, pretrain_loss(손실): 0.018393\n",
      "반복(epoch):87, pretrain_loss(손실): 0.017157\n",
      "반복(epoch):88, pretrain_loss(손실): 0.018054\n",
      "반복(epoch):89, pretrain_loss(손실): 0.016287\n",
      "반복(epoch):90, pretrain_loss(손실): 0.018610\n",
      "반복(epoch):91, pretrain_loss(손실): 0.016822\n",
      "반복(epoch):92, pretrain_loss(손실): 0.016714\n",
      "반복(epoch):93, pretrain_loss(손실): 0.017396\n",
      "반복(epoch):94, pretrain_loss(손실): 0.016309\n",
      "반복(epoch):95, pretrain_loss(손실): 0.017289\n",
      "반복(epoch):96, pretrain_loss(손실): 0.015805\n",
      "반복(epoch):97, pretrain_loss(손실): 0.017670\n",
      "반복(epoch):98, pretrain_loss(손실): 0.015960\n",
      "반복(epoch):99, pretrain_loss(손실): 0.017587\n",
      "반복(epoch):100, pretrain_loss(손실): 0.015882\n",
      "step1: MNIST 데이터 재구축을 위한 오토인코더 최적화 완료\n",
      "반복(epoch):1, fine_tuning_loss(손실):0.473298\n",
      "반복(epoch):2, fine_tuning_loss(손실):0.431636\n",
      "반복(epoch):3, fine_tuning_loss(손실):0.315498\n",
      "반복(epoch):4, fine_tuning_loss(손실):0.288241\n",
      "반복(epoch):5, fine_tuning_loss(손실):0.281770\n",
      "반복(epoch):6, fine_tuning_loss(손실):0.153729\n",
      "반복(epoch):7, fine_tuning_loss(손실):0.255078\n",
      "반복(epoch):8, fine_tuning_loss(손실):0.257323\n",
      "반복(epoch):9, fine_tuning_loss(손실):0.245104\n",
      "반복(epoch):10, fine_tuning_loss(손실):0.210675\n",
      "반복(epoch):11, fine_tuning_loss(손실):0.174314\n",
      "반복(epoch):12, fine_tuning_loss(손실):0.210400\n",
      "반복(epoch):13, fine_tuning_loss(손실):0.225288\n",
      "반복(epoch):14, fine_tuning_loss(손실):0.191608\n",
      "반복(epoch):15, fine_tuning_loss(손실):0.150164\n",
      "반복(epoch):16, fine_tuning_loss(손실):0.178780\n",
      "반복(epoch):17, fine_tuning_loss(손실):0.144242\n",
      "반복(epoch):18, fine_tuning_loss(손실):0.174866\n",
      "반복(epoch):19, fine_tuning_loss(손실):0.174860\n",
      "반복(epoch):20, fine_tuning_loss(손실):0.147595\n",
      "반복(epoch):21, fine_tuning_loss(손실):0.132986\n",
      "반복(epoch):22, fine_tuning_loss(손실):0.147831\n",
      "반복(epoch):23, fine_tuning_loss(손실):0.113895\n",
      "반복(epoch):24, fine_tuning_loss(손실):0.232708\n",
      "반복(epoch):25, fine_tuning_loss(손실):0.192035\n",
      "반복(epoch):26, fine_tuning_loss(손실):0.092940\n",
      "반복(epoch):27, fine_tuning_loss(손실):0.128941\n",
      "반복(epoch):28, fine_tuning_loss(손실):0.178228\n",
      "반복(epoch):29, fine_tuning_loss(손실):0.144221\n",
      "반복(epoch):30, fine_tuning_loss(손실):0.113586\n",
      "반복(epoch):31, fine_tuning_loss(손실):0.111283\n",
      "반복(epoch):32, fine_tuning_loss(손실):0.112223\n",
      "반복(epoch):33, fine_tuning_loss(손실):0.104385\n",
      "반복(epoch):34, fine_tuning_loss(손실):0.090976\n",
      "반복(epoch):35, fine_tuning_loss(손실):0.078459\n",
      "반복(epoch):36, fine_tuning_loss(손실):0.098753\n",
      "반복(epoch):37, fine_tuning_loss(손실):0.198737\n",
      "반복(epoch):38, fine_tuning_loss(손실):0.103109\n",
      "반복(epoch):39, fine_tuning_loss(손실):0.079336\n",
      "반복(epoch):40, fine_tuning_loss(손실):0.101532\n",
      "반복(epoch):41, fine_tuning_loss(손실):0.121422\n",
      "반복(epoch):42, fine_tuning_loss(손실):0.064972\n",
      "반복(epoch):43, fine_tuning_loss(손실):0.062791\n",
      "반복(epoch):44, fine_tuning_loss(손실):0.061910\n",
      "반복(epoch):45, fine_tuning_loss(손실):0.110194\n",
      "반복(epoch):46, fine_tuning_loss(손실):0.095895\n",
      "반복(epoch):47, fine_tuning_loss(손실):0.073270\n",
      "반복(epoch):48, fine_tuning_loss(손실):0.100478\n",
      "반복(epoch):49, fine_tuning_loss(손실):0.089628\n",
      "반복(epoch):50, fine_tuning_loss(손실):0.137498\n",
      "반복(epoch):51, fine_tuning_loss(손실):0.049123\n",
      "반복(epoch):52, fine_tuning_loss(손실):0.046361\n",
      "반복(epoch):53, fine_tuning_loss(손실):0.120249\n",
      "반복(epoch):54, fine_tuning_loss(손실):0.074233\n",
      "반복(epoch):55, fine_tuning_loss(손실):0.089767\n",
      "반복(epoch):56, fine_tuning_loss(손실):0.077209\n",
      "반복(epoch):57, fine_tuning_loss(손실):0.141965\n",
      "반복(epoch):58, fine_tuning_loss(손실):0.080273\n",
      "반복(epoch):59, fine_tuning_loss(손실):0.082868\n",
      "반복(epoch):60, fine_tuning_loss(손실):0.071953\n",
      "반복(epoch):61, fine_tuning_loss(손실):0.058899\n",
      "반복(epoch):62, fine_tuning_loss(손실):0.057954\n",
      "반복(epoch):63, fine_tuning_loss(손실):0.072960\n",
      "반복(epoch):64, fine_tuning_loss(손실):0.040374\n",
      "반복(epoch):65, fine_tuning_loss(손실):0.058518\n",
      "반복(epoch):66, fine_tuning_loss(손실):0.036259\n",
      "반복(epoch):67, fine_tuning_loss(손실):0.081725\n",
      "반복(epoch):68, fine_tuning_loss(손실):0.055377\n",
      "반복(epoch):69, fine_tuning_loss(손실):0.047804\n",
      "반복(epoch):70, fine_tuning_loss(손실):0.038972\n",
      "반복(epoch):71, fine_tuning_loss(손실):0.044523\n",
      "반복(epoch):72, fine_tuning_loss(손실):0.072108\n",
      "반복(epoch):73, fine_tuning_loss(손실):0.067381\n",
      "반복(epoch):74, fine_tuning_loss(손실):0.055478\n",
      "반복(epoch):75, fine_tuning_loss(손실):0.050128\n",
      "반복(epoch):76, fine_tuning_loss(손실):0.034389\n",
      "반복(epoch):77, fine_tuning_loss(손실):0.056685\n",
      "반복(epoch):78, fine_tuning_loss(손실):0.064071\n",
      "반복(epoch):79, fine_tuning_loss(손실):0.062099\n",
      "반복(epoch):80, fine_tuning_loss(손실):0.051672\n",
      "반복(epoch):81, fine_tuning_loss(손실):0.063432\n",
      "반복(epoch):82, fine_tuning_loss(손실):0.038576\n",
      "반복(epoch):83, fine_tuning_loss(손실):0.036136\n",
      "반복(epoch):84, fine_tuning_loss(손실):0.020908\n",
      "반복(epoch):85, fine_tuning_loss(손실):0.027319\n",
      "반복(epoch):86, fine_tuning_loss(손실):0.067683\n",
      "반복(epoch):87, fine_tuning_loss(손실):0.049675\n",
      "반복(epoch):88, fine_tuning_loss(손실):0.049381\n",
      "반복(epoch):89, fine_tuning_loss(손실):0.072459\n",
      "반복(epoch):90, fine_tuning_loss(손실):0.057213\n",
      "반복(epoch):91, fine_tuning_loss(손실):0.034475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "반복(epoch):92, fine_tuning_loss(손실):0.032250\n",
      "반복(epoch):93, fine_tuning_loss(손실):0.036786\n",
      "반복(epoch):94, fine_tuning_loss(손실):0.038612\n",
      "반복(epoch):95, fine_tuning_loss(손실):0.037038\n",
      "반복(epoch):96, fine_tuning_loss(손실):0.026153\n",
      "반복(epoch):97, fine_tuning_loss(손실):0.038301\n",
      "반복(epoch):98, fine_tuning_loss(손실):0.084209\n",
      "반복(epoch):99, fine_tuning_loss(손실):0.029764\n",
      "반복(epoch):100, fine_tuning_loss(손실):0.047113\n",
      "반복(epoch):101, fine_tuning_loss(손실):0.033317\n",
      "반복(epoch):102, fine_tuning_loss(손실):0.033871\n",
      "반복(epoch):103, fine_tuning_loss(손실):0.035705\n",
      "반복(epoch):104, fine_tuning_loss(손실):0.047846\n",
      "반복(epoch):105, fine_tuning_loss(손실):0.018035\n",
      "반복(epoch):106, fine_tuning_loss(손실):0.027655\n",
      "반복(epoch):107, fine_tuning_loss(손실):0.034073\n",
      "반복(epoch):108, fine_tuning_loss(손실):0.056265\n",
      "반복(epoch):109, fine_tuning_loss(손실):0.021892\n",
      "반복(epoch):110, fine_tuning_loss(손실):0.032974\n",
      "반복(epoch):111, fine_tuning_loss(손실):0.018196\n",
      "반복(epoch):112, fine_tuning_loss(손실):0.045273\n",
      "반복(epoch):113, fine_tuning_loss(손실):0.026624\n",
      "반복(epoch):114, fine_tuning_loss(손실):0.042835\n",
      "반복(epoch):115, fine_tuning_loss(손실):0.032979\n",
      "반복(epoch):116, fine_tuning_loss(손실):0.021128\n",
      "반복(epoch):117, fine_tuning_loss(손실):0.020280\n",
      "반복(epoch):118, fine_tuning_loss(손실):0.038094\n",
      "반복(epoch):119, fine_tuning_loss(손실):0.031894\n",
      "반복(epoch):120, fine_tuning_loss(손실):0.028952\n",
      "반복(epoch):121, fine_tuning_loss(손실):0.024474\n",
      "반복(epoch):122, fine_tuning_loss(손실):0.011602\n",
      "반복(epoch):123, fine_tuning_loss(손실):0.017791\n",
      "반복(epoch):124, fine_tuning_loss(손실):0.028681\n",
      "반복(epoch):125, fine_tuning_loss(손실):0.045410\n",
      "반복(epoch):126, fine_tuning_loss(손실):0.048755\n",
      "반복(epoch):127, fine_tuning_loss(손실):0.023540\n",
      "반복(epoch):128, fine_tuning_loss(손실):0.019140\n",
      "반복(epoch):129, fine_tuning_loss(손실):0.025999\n",
      "반복(epoch):130, fine_tuning_loss(손실):0.051282\n",
      "반복(epoch):131, fine_tuning_loss(손실):0.015772\n",
      "반복(epoch):132, fine_tuning_loss(손실):0.010924\n",
      "반복(epoch):133, fine_tuning_loss(손실):0.021076\n",
      "반복(epoch):134, fine_tuning_loss(손실):0.025417\n",
      "반복(epoch):135, fine_tuning_loss(손실):0.017977\n",
      "반복(epoch):136, fine_tuning_loss(손실):0.032805\n",
      "반복(epoch):137, fine_tuning_loss(손실):0.019933\n",
      "반복(epoch):138, fine_tuning_loss(손실):0.021719\n",
      "반복(epoch):139, fine_tuning_loss(손실):0.036837\n",
      "반복(epoch):140, fine_tuning_loss(손실):0.011755\n",
      "반복(epoch):141, fine_tuning_loss(손실):0.040995\n",
      "반복(epoch):142, fine_tuning_loss(손실):0.018205\n",
      "반복(epoch):143, fine_tuning_loss(손실):0.055196\n",
      "반복(epoch):144, fine_tuning_loss(손실):0.022866\n",
      "반복(epoch):145, fine_tuning_loss(손실):0.025857\n",
      "반복(epoch):146, fine_tuning_loss(손실):0.012573\n",
      "반복(epoch):147, fine_tuning_loss(손실):0.032650\n",
      "반복(epoch):148, fine_tuning_loss(손실):0.023404\n",
      "반복(epoch):149, fine_tuning_loss(손실):0.027769\n",
      "반복(epoch):150, fine_tuning_loss(손실):0.014468\n",
      "반복(epoch):151, fine_tuning_loss(손실):0.017714\n",
      "반복(epoch):152, fine_tuning_loss(손실):0.023234\n",
      "반복(epoch):153, fine_tuning_loss(손실):0.019392\n",
      "반복(epoch):154, fine_tuning_loss(손실):0.023135\n",
      "반복(epoch):155, fine_tuning_loss(손실):0.023106\n",
      "반복(epoch):156, fine_tuning_loss(손실):0.010265\n",
      "반복(epoch):157, fine_tuning_loss(손실):0.023944\n",
      "반복(epoch):158, fine_tuning_loss(손실):0.008208\n",
      "반복(epoch):159, fine_tuning_loss(손실):0.016867\n",
      "반복(epoch):160, fine_tuning_loss(손실):0.034398\n",
      "반복(epoch):161, fine_tuning_loss(손실):0.012992\n",
      "반복(epoch):162, fine_tuning_loss(손실):0.018128\n",
      "반복(epoch):163, fine_tuning_loss(손실):0.021744\n",
      "반복(epoch):164, fine_tuning_loss(손실):0.027411\n",
      "반복(epoch):165, fine_tuning_loss(손실):0.015861\n",
      "반복(epoch):166, fine_tuning_loss(손실):0.010897\n",
      "반복(epoch):167, fine_tuning_loss(손실):0.030658\n",
      "반복(epoch):168, fine_tuning_loss(손실):0.013377\n",
      "반복(epoch):169, fine_tuning_loss(손실):0.008868\n",
      "반복(epoch):170, fine_tuning_loss(손실):0.023339\n",
      "반복(epoch):171, fine_tuning_loss(손실):0.010121\n",
      "반복(epoch):172, fine_tuning_loss(손실):0.021370\n",
      "반복(epoch):173, fine_tuning_loss(손실):0.014197\n",
      "반복(epoch):174, fine_tuning_loss(손실):0.010475\n",
      "반복(epoch):175, fine_tuning_loss(손실):0.010334\n",
      "반복(epoch):176, fine_tuning_loss(손실):0.018983\n",
      "반복(epoch):177, fine_tuning_loss(손실):0.011348\n",
      "반복(epoch):178, fine_tuning_loss(손실):0.013910\n",
      "반복(epoch):179, fine_tuning_loss(손실):0.009269\n",
      "반복(epoch):180, fine_tuning_loss(손실):0.010323\n",
      "반복(epoch):181, fine_tuning_loss(손실):0.013047\n",
      "반복(epoch):182, fine_tuning_loss(손실):0.029285\n",
      "반복(epoch):183, fine_tuning_loss(손실):0.012859\n",
      "반복(epoch):184, fine_tuning_loss(손실):0.009113\n",
      "반복(epoch):185, fine_tuning_loss(손실):0.007997\n",
      "반복(epoch):186, fine_tuning_loss(손실):0.029032\n",
      "반복(epoch):187, fine_tuning_loss(손실):0.010723\n",
      "반복(epoch):188, fine_tuning_loss(손실):0.009333\n",
      "반복(epoch):189, fine_tuning_loss(손실):0.012013\n",
      "반복(epoch):190, fine_tuning_loss(손실):0.014467\n",
      "반복(epoch):191, fine_tuning_loss(손실):0.022479\n",
      "반복(epoch):192, fine_tuning_loss(손실):0.011503\n",
      "반복(epoch):193, fine_tuning_loss(손실):0.012173\n",
      "반복(epoch):194, fine_tuning_loss(손실):0.011582\n",
      "반복(epoch):195, fine_tuning_loss(손실):0.015203\n",
      "반복(epoch):196, fine_tuning_loss(손실):0.011439\n",
      "반복(epoch):197, fine_tuning_loss(손실):0.011236\n",
      "반복(epoch):198, fine_tuning_loss(손실):0.008005\n",
      "반복(epoch):199, fine_tuning_loss(손실):0.030436\n",
      "반복(epoch):200, fine_tuning_loss(손실):0.012304\n",
      "step2: MNIST 데이터 분류를 위한 오토인코더 + 소프트 맥스 분류기 최적화 완료\n",
      "정확도:0.962000\n"
     ]
    }
   ],
   "source": [
    "# 셰션을 열고 그래프를 실행\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    total_batch=int(mnist.train.num_examples/batch_size)\n",
    "    # 1. minst 데이터 재구축을 위한 오토인코더 최적화(pre-training)\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            _,pretraining_loss_print=sess.run([pretraining_train_step,pretraining_loss],feed_dict={x:batch_xs,y:batch_ys})\n",
    "            \n",
    "        if epoch % display_step ==0:\n",
    "            print(\"반복(epoch):%d, pretrain_loss(손실): %f\" % ((epoch+1),pretraining_loss_print))\n",
    "    print(\"step1: MNIST 데이터 재구축을 위한 오토인코더 최적화 완료\")\n",
    "    \n",
    "    # 2. mnist 데이터 분류를 위한 오토인코더 + softmax 분류기 최적화(fine_tuning)\n",
    "    for epoch in range(num_epochs+100):\n",
    "        \n",
    "        for i in range(total_batch):\n",
    "            batch_xs,batch_ys=mnist.train.next_batch(batch_size)\n",
    "            _,finetuning_loss_print=sess.run([finetuning_train_step,finetuning_loss],feed_dict={x:batch_xs,y:batch_ys})\n",
    "        \n",
    "        print(\"반복(epoch):%d, fine_tuning_loss(손실):%f\" % ((epoch+1),finetuning_loss_print))\n",
    "        \n",
    "    print(\"step2: MNIST 데이터 분류를 위한 오토인코더 + 소프트 맥스 분류기 최적화 완료\")\n",
    "    \n",
    "    \n",
    "    correct_prediction=tf.equal(tf.argmax(y,1),tf.argmax(y_pred_softmax,1))\n",
    "    accuracy=tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "    print(\"정확도:%f\" % sess.run(accuracy,feed_dict={x:mnist.test.images, y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "import numpy as np\n",
    "\n",
    "# 임의로 선택한 10개의 MNIST 데이터를 화면에 보여준다.\n",
    "for c in range(1, 11):\n",
    "    subplot(2, 5, c)\n",
    "    i = randint(mnist.test.num_examples)\n",
    "    im = np.reshape(mnist.test.images[i], [28, 28])\n",
    "    axis(\"off\")\n",
    "    imshow(im, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f,a=plt.subplots(2,10,figsize=(10,2))\n",
    "    for i in range(example_show):\n",
    "        a[0][i].imshow(np.reshape(mnist.test.images[i],(28,28)))\n",
    "        a[1][i].imshow(np.reshape(reconstucted_result[i],(28,28)))\n",
    "                       \n",
    "    f.show()\n",
    "    plt.draw()\n",
    "    plt.waitforbuttonpress()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
