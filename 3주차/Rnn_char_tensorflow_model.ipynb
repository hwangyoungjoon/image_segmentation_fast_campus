{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib import rnn\n",
    "from tensorflow.contrib import legacy_seq2seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model():\n",
    "    def __init__(self,args,training=True):\n",
    "        self.args=args\n",
    "        if not training:\n",
    "            args.batch_size=1\n",
    "            args.seq_length=1\n",
    "            \n",
    "        if args.model=='rnn':\n",
    "            cell_fn=rnn.BasicRNNCell\n",
    "        elif args.model=='gru':\n",
    "            cell_fn=rnn.GRUCell\n",
    "        elif args.model ==\"lstm\":\n",
    "            cell_fn=rnn.BasicLSTMCell\n",
    "        elif args.model == \"nas\":\n",
    "            cell_fn=rnn.NASCell\n",
    "        else:\n",
    "            raise Exception(\"model type not supproted: {}\".format(args.model))\n",
    "            \n",
    "        cells=[]\n",
    "        \n",
    "        for _ in range(args.num_layers):\n",
    "            cell=cell_fn(args.rnn_size)\n",
    "            if training and (args.output_keep_prob < 1.0 or args.input_keep_prob < 1.0):\n",
    "                cell=rnn.DropoutWrapper(cell,\n",
    "                                       input_keep_prob=args.input_keep_prob,\n",
    "                                       output_keep_prob=args.output_keep_prob)\n",
    "            cells.append(cell)\n",
    "            \n",
    "        self.cell= cell=rnn.MultiRNNCell(cells,state_is_tuple=True)\n",
    "        \n",
    "        self.input_data=tf.placeholder(tf.int32,[args.batch_size,args.seq_length])\n",
    "        self.targets=tf.placeholder(tf.int32,[args.batch_size,args.seq_length])\n",
    "        self.initial_state=cell.zero_state(args.batch_size,tf.float32)\n",
    "        \n",
    "        with tf.variabel_scope('rnnlm'):\n",
    "            softmax_w=tf.get_variable(\"softmax_w\",[args.rnn_size,args.vocab_size])\n",
    "            softmax_b=tf.get_variable(\"softmax_b\",[args.vocab_size])\n",
    "            \n",
    "        embedding=tf.get_variable(\"embedding\",[args.vocab_size,args.rnn_size])\n",
    "        inputs=tf.nn.embedding_lookup(embedding,self.input_data)\n",
    "        \n",
    "        \n",
    "        # 드랍아웃 베타 테스트\n",
    "        if training and args.output_keep_prob:\n",
    "            inputs=tf.nn.dropout(inputs,args.output_keep_prob)\n",
    "            \n",
    "        inputs=tf.split(inputs,args.seq_length,1)\n",
    "        inputs=[tf.squeeze(input_,[1]) for input_ in inputs]\n",
    "        \n",
    "        def loop(prev,_):\n",
    "            prev=tf.matmul(prev,softmax_w)+softmax_b\n",
    "            prev_symbol=tf.stop_gradient(tf.argmax(prev,1))\n",
    "            return tf.nn.embedding_lookup(embedding,prev_symbol)\n",
    "        \n",
    "        outputs, last_state=legacy_seq2seq.rnn_decoder(inputs,self.initial_state,cell,\n",
    "                                                       loop_function=loop if not training else None, scope='rnnlm')\n",
    "        output=tf.reshape(tf.concat(outputs,1),[-1,args.rnn_size])\n",
    "        \n",
    "        self.logits=tf.matmul(output,softmax_w)+softmax_b\n",
    "        self.probs=tf.nn.softmax(self.logits)\n",
    "        \n",
    "        loss=legacy_seq2seq.sequence_loss_by_example([self.logits],\n",
    "                                                    [tf.reshape(self.targets,[-1])],\n",
    "                                                    [tf.ones([args.batch_size*args.seq_length])])\n",
    "        self.cost=tf.reduce_sum(loss)/args.batch_size/args.seq_length\n",
    "        \n",
    "        with tf.name_scope('cost'):\n",
    "            self.cost=tf.reduce_sum(loss)/args.batch_size/args.seq_length\n",
    "        self.final_state=last_state\n",
    "        self.lr=tf.Variable(0.0,trainable=False)\n",
    "        tvars=tf.trainable_variables()\n",
    "        grads,_= tf.clip_by_global_norm(tf.gradients(self.cost,tvars),args.grad_clip)\n",
    "        with tf.name_scope('optimizer'):\n",
    "            optimizer=tf.train.AdamOptimizer(self.lr)\n",
    "        self.train_op=optimizer.apply_gradients(zip(grads,tvars))\n",
    "        \n",
    "        \n",
    "        # 텐서보드 이용\n",
    "        tf.summary.histogram('logits',self.logits)\n",
    "        tf.summary.histogram('loss',loss)\n",
    "        tf.summary.scalar('train_loss',self.cost)\n",
    "        \n",
    "    def sample(self,sess,chars,vocab,num=200,prime='The ',sampling_type=1):\n",
    "        state=sess.run(self.cell.zero_state(1,tf.float32))\n",
    "        for char in prime[:-1]:\n",
    "            x=np.zeros(1,1)\n",
    "            x[0,0]=vocab[char]\n",
    "            feed={self.input_data:x, self.initial_state: state}\n",
    "            [state]=sess.run([self.final_state],feed)\n",
    "            \n",
    "        def weighted_pick(weights):\n",
    "            t=np.cumsum(weights)\n",
    "            s=np.sum(weights)\n",
    "            return(int(np.searchsorted(t,np.random.rand(1)*s)))\n",
    "        \n",
    "        ret=prime\n",
    "        char=prime[-1]\n",
    "        for n in range(num):\n",
    "            x=np.zeros((1,1))\n",
    "            x[0,0]=vocab[char]\n",
    "            feed={self.input_data:x, self_initial_state:state}\n",
    "            [probs,state]=sess.run([self.probs,self.final_state],feed)\n",
    "            p=probs[0]\n",
    "            \n",
    "            if sampling_type==0:\n",
    "                sample=np.argmax(p)\n",
    "            elif sampling_type==2:\n",
    "                if char == '':\n",
    "                    sample=weighted_pick(p)\n",
    "                else:\n",
    "                    sample=np.argmax(p)\n",
    "            else:\n",
    "                sample=weighted_pick(p)\n",
    "            \n",
    "            pred=chars[sample]\n",
    "            ret+=pred\n",
    "            char=pred\n",
    "        \n",
    "        return ret"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
